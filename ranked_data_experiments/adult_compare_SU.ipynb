{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys; sys.path.insert(0,'..')\n",
    "from main import *\n",
    "\n",
    "from SU_Classification.su_learning import SU_SL, SU_DH, convert_su_data_sklearn_compatible\n",
    "from SU_Classification import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_svmlight_file('../data/adult/a5a.txt', n_features=123)\n",
    "X_train = X_train.toarray()\n",
    "\n",
    "X_test, y_test = load_svmlight_file('../data/adult/a5a.t')\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SU Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s = 500\n",
    "n_u = 500\n",
    "\n",
    "# Sizes of sets to sample similar, unlabeled points\n",
    "train_size = 5000\n",
    "su_cutoff  = 2500\n",
    "\n",
    "# Only use some of training data\n",
    "train_samples = np.random.permutation(X_train.shape[0])[:train_size]\n",
    "X_train = X_train[train_samples]\n",
    "y_train = y_train[train_samples]\n",
    "\n",
    "# Sample similar and unlabeled points from disjoint sets\n",
    "X_s_set = X_train[:su_cutoff]\n",
    "y_s_set = y_train[:su_cutoff]\n",
    "X_u_set = X_train[su_cutoff:]\n",
    "y_u_set = y_train[su_cutoff:]\n",
    "\n",
    "# Get positive pairs and negative pairs\n",
    "X_pos = X_s_set[np.where(y_s_set ==  1)]\n",
    "X_neg = X_s_set[np.where(y_s_set == -1)]\n",
    "\n",
    "X_pos_idx = np.random.choice(X_pos.shape[0], size=(int(n_s / 2), 2))\n",
    "X_neg_idx = np.random.choice(X_neg.shape[0], size=(int(n_s / 2), 2))\n",
    "\n",
    "# Fill in similar pairs\n",
    "X_s = np.full((n_s, X_train.shape[1] * 2), np.NaN)\n",
    "\n",
    "k = 0\n",
    "for (i, j) in X_pos_idx:\n",
    "    X_s[k] = np.hstack((X_pos[i], X_pos[j]))\n",
    "    k += 1\n",
    "    \n",
    "for (i, j) in X_neg_idx:\n",
    "    X_s[k] =np.hstack((X_neg[i], X_neg[j]))\n",
    "    k += 1\n",
    "\n",
    "# Fill in unlabeled samples\n",
    "unlabeled_samples = np.random.permutation(X_u_set.shape[0])[:n_u]\n",
    "X_u = X_u_set[unlabeled_samples]\n",
    "\n",
    "X_train, y_train = convert_su_data_sklearn_compatible(X_s, X_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.8 ms, sys: 14.2 ms, total: 73 ms\n",
      "Wall time: 42.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.45726087122805675,\n",
       " (array([-1.,  1.]), array([15716, 10431])),\n",
       " (array([-1.,  1.]), array([19875,  6272])))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = SU_SL(prior=0.3, lam=1e-04)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred), np.unique(y_pred, return_counts=True), np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1., -1., -1., ..., -1., -1.,  1.]),\n",
       " array([-1., -1., -1., ...,  1., -1., -1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(n, dim, mean=2, var=1):\n",
    "    return np.random.normal(mean, var, size=(n, dim))\n",
    "\n",
    "def synth_dataset(ns, nu, prior, nt, dim=2, mp=2):\n",
    "    nsp = np.random.binomial(ns, prior**2 / (prior**2 + (1-prior)**2))\n",
    "    nsn = ns - nsp\n",
    "    xsp = np.hstack((gen(nsp, dim,mean=mp), gen(nsp, dim,mean=mp)))\n",
    "    xsn = np.hstack((gen(nsn, dim, mean=-mp), gen(nsn, dim, mean=-mp)))\n",
    "    xs = np.concatenate((xsp,xsn))\n",
    "    xsr = np.concatenate((xsp.reshape(-1, dim),xsn.reshape(-1, dim)))\n",
    "    yr = np.concatenate((np.ones(2*nsp),-np.ones(2*nsn)))\n",
    "    \n",
    "\n",
    "    nup = np.random.binomial(nu, prior)\n",
    "    nun = nu - nup\n",
    "    xu = np.concatenate((gen(nup, dim,mean=mp), gen(nun, dim,mean=-mp)))\n",
    "    yu = np.concatenate((np.ones(nup), -np.ones(nun)))\n",
    "    \n",
    "    x_train = np.concatenate((xsr,xu))\n",
    "    y_train = np.concatenate((yr,yu))\n",
    "    x_train,y_train = shuffle(x_train,y_train)\n",
    "    \n",
    "    \n",
    "    ntp = np.random.binomial(nt, prior)\n",
    "    ntn = nt - ntp\n",
    "    x_test = np.concatenate((gen(ntp, dim,mean=mp), gen(ntn, dim,mean=-mp)))\n",
    "    y_test = np.concatenate((np.ones(ntp), -np.ones(ntn)))\n",
    "\n",
    "    return xs, xu, x_train, y_train, x_test, y_test\n",
    "\n",
    "x_s, x_u, x_train, y_train, x_test, y_test = synth_dataset(ns=n_s, nu=n_u, prior=0.6, nt=100, mp=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 ms, sys: 1.33 ms, total: 4.23 ms\n",
      "Wall time: 2.96 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "x_train_su, y_train_su = convert_su_data_sklearn_compatible(x_s, x_u)\n",
    "\n",
    "clf = SU_SL(prior=0.7, lam=1e-01)\n",
    "clf.fit(x_train_su, y_train_su)\n",
    "\n",
    "y_pred = clf.predict(x_test).ravel()\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-1.,  1.]), array([34, 66])), (array([-1.,  1.]), array([46, 54])))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred, return_counts=True), np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "         1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "        -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "         1., -1.,  1., -1., -1., -1., -1., -1.,  1.]),\n",
       " array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s = 500\n",
    "n_u = 500\n",
    "\n",
    "# Sizes of sets to sample similar, unlabeled points\n",
    "train_size = 5000\n",
    "su_cutoff  = 2500\n",
    "\n",
    "# Only use some of training data\n",
    "train_samples = np.random.permutation(X_train.shape[0])[:train_size]\n",
    "X_train = X_train[train_samples]\n",
    "y_train = y_train[train_samples]\n",
    "\n",
    "# Sample similar and unlabeled points from disjoint sets\n",
    "X_s_set = X_train[:su_cutoff]\n",
    "y_s_set = y_train[:su_cutoff]\n",
    "X_u_set = X_train[su_cutoff:]\n",
    "y_u_set = y_train[su_cutoff:]\n",
    "\n",
    "# Get positive pairs and negative pairs\n",
    "X_pos = X_s_set[np.where(y_s_set ==  1)]\n",
    "X_neg = X_s_set[np.where(y_s_set == -1)]\n",
    "\n",
    "X_pos_idx = np.random.choice(X_pos.shape[0], size=(int(n_s / 2), 2))\n",
    "X_neg_idx = np.random.choice(X_neg.shape[0], size=(int(n_s / 2), 2))\n",
    "\n",
    "# Fill in similar pairs\n",
    "X_s = np.full((n_s, X_train.shape[1] * 2), np.NaN)\n",
    "\n",
    "k = 0\n",
    "for (i, j) in X_pos_idx:\n",
    "    X_s[k] = np.hstack((X_pos[i], X_pos[j]))\n",
    "    k += 1\n",
    "    \n",
    "for (i, j) in X_neg_idx:\n",
    "    X_s[k] =np.hstack((X_neg[i], X_neg[j]))\n",
    "    k += 1\n",
    "\n",
    "# Fill in unlabeled samples\n",
    "unlabeled_samples = np.random.permutation(X_u_set.shape[0])[:n_u]\n",
    "X_u = X_u_set[unlabeled_samples]\n",
    "\n",
    "X_train, y_train = convert_su_data_sklearn_compatible(X_s, X_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-66f0b1a366a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m xs = np.concatenate((np.hstack((X_s_pos[np.random.choice(X_s_pos.shape[0], nsp)], \n\u001b[1;32m     36\u001b[0m                                X_s_pos[np.random.choice(X_s_pos.shape[0], nsp)])),\n\u001b[0;32m---> 37\u001b[0;31m                     np.hstack((X_s_neg[np.random.choice(X_s_neg.shape[0], nsn)], \n\u001b[0m\u001b[1;32m     38\u001b[0m                                X_s_neg[np.random.choice(X_s_neg.shape[0], nsn)]))))\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# ns = 500\n",
    "# nu = 500\n",
    "# prior = 0.3\n",
    "\n",
    "prior = 0.7\n",
    "\n",
    "ns = 500\n",
    "nu = 500\n",
    "\n",
    "# Sizes of sets to sample similar, unlabeled points\n",
    "train_size = 5000\n",
    "su_cutoff  = 2500\n",
    "\n",
    "# Only use some of training data\n",
    "train_samples = np.random.permutation(X_train.shape[0])[:train_size]\n",
    "X_train = X_train[train_samples]\n",
    "y_train = y_train[train_samples]\n",
    "\n",
    "# Sample similar and unlabeled points from disjoint sets\n",
    "X_s_set = X_train[:su_cutoff]\n",
    "y_s_set = y_train[:su_cutoff]\n",
    "X_u_set = X_train[su_cutoff:]\n",
    "y_u_set = y_train[su_cutoff:]\n",
    "\n",
    "# Similar: get positive pairs and negative pairs\n",
    "X_s_pos = X_s_set[np.where(y_s_set ==  1)]\n",
    "X_s_neg = X_s_set[np.where(y_s_set == -1)]\n",
    "\n",
    "nsp = np.random.binomial(ns, prior**2 / (prior**2 + (1-prior)**2))\n",
    "nsn = ns - nsp\n",
    "# xs = np.concatenate((\n",
    "#     np.hstack((gen1(nsp, dim), gen1(nsp, dim))),\n",
    "#     np.hstack((gen0(nsn, dim), gen0(nsn, dim)))))\n",
    "\n",
    "xs = np.concatenate((np.hstack((X_s_pos[np.random.choice(X_s_pos.shape[0], nsp)], \n",
    "                               X_s_pos[np.random.choice(X_s_pos.shape[0], nsp)])),\n",
    "                    np.hstack((X_s_neg[np.random.choice(X_s_neg.shape[0], nsn)], \n",
    "                               X_s_neg[np.random.choice(X_s_neg.shape[0], nsn)]))))\n",
    "\n",
    "nup = np.random.binomial(nu, prior)\n",
    "nun = nu - nup\n",
    "# xu = np.concatenate((gen1(nup, dim), gen0(nun, dim)))\n",
    "\n",
    "X_u_pos = X_u_set[np.where(y_u_set ==  1)]\n",
    "X_u_neg = X_u_set[np.where(y_u_set == -1)]\n",
    "\n",
    "xu = np.concatenate((X_u_pos[np.random.choice(X_u_pos.shape[0], nup)], \n",
    "                     X_u_neg[np.random.choice(X_u_neg.shape[0], nun)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, y_train = convert_su_data_sklearn_compatible(xs, xu)\n",
    "\n",
    "clf = SU_SL(prior=0.7, lam=1e-04)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred), np.unique(y_pred, return_counts=True), np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape, xu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_dataset(ns, nu, prior, dim=2):\n",
    "    nsp = np.random.binomial(ns, prior**2 / (prior**2 + (1-prior)**2))\n",
    "    nsn = ns - nsp\n",
    "    xs = np.concatenate((\n",
    "        np.hstack((gen1(nsp, dim), gen1(nsp, dim))),\n",
    "        np.hstack((gen0(nsn, dim), gen0(nsn, dim)))))\n",
    "\n",
    "    nup = np.random.binomial(nu, prior)\n",
    "    nun = nu - nup\n",
    "    xu = np.concatenate((gen1(nup, dim), gen0(nun, dim)))\n",
    "\n",
    "    return xs, xu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
